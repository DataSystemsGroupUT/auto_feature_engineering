{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/autofeatures/venv/lib/python3.6/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    }
   ],
   "source": [
    "import sklearn.model_selection\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import pandas as pd\n",
    "import autosklearn.classification\n",
    "import os\n",
    "import featuretools as ft\n",
    "import warnings\n",
    "import autofeat \n",
    "from tpot import TPOTClassifier\n",
    "import json \n",
    "import time\n",
    "from sklearn import preprocessing \n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from dask.distributed import Client\n",
    "#client = Client(n_workers=6, threads_per_worker=1, memory_limit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_as(X, y, target_ft, time_budget=30, include_preprocessors = None, n_jobs=-1):\n",
    "    try:\n",
    "        os.remove('/tmp/autosklearn_regression_example_tmp')\n",
    "        os.remove('/tmp/autosklearn_regression_example_out')\n",
    "    except:\n",
    "        pass\n",
    "    #X = df.drop(columns=target_ft)\n",
    "    #y = df[target_ft]\n",
    "    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state=1)\n",
    "    automl = autosklearn.classification.AutoSklearnClassifier(\n",
    "        time_left_for_this_task=time_budget,\n",
    "        #per_run_time_limit=30,\n",
    "        tmp_folder='./tmp/autosklearn_regression_example_tmp',\n",
    "        output_folder='./tmp/autosklearn_regression_example_out',\n",
    "        include_preprocessors=include_preprocessors,\n",
    "        ml_memory_limit=None,\n",
    "        ensemble_memory_limit=None,\n",
    "        metric=autosklearn.metrics.f1_weighted,\n",
    "        n_jobs=n_jobs\n",
    "    )\n",
    "    automl.fit(X_train, y_train)\n",
    "    y_hat = automl.predict(X_test)\n",
    "    \n",
    "    acc = sklearn.metrics.accuracy_score(y_test, y_hat)\n",
    "    f1_s = sklearn.metrics.f1_score(y_test, y_hat, average='weighted')\n",
    "    metrs = []\n",
    "    metrs.append(\"Accuracy score - \" + str(acc))\n",
    "    metrs.append(\"F1 score - \" + str(f1_s))\n",
    "    \n",
    "    res = [\"\",\"\",\"\",\"\",f1_s,acc,\"\",automl.show_models()]\n",
    "    \n",
    "    \n",
    "    return str(metrs),res\n",
    "\n",
    "def run_tpot(X,y, target_ft,time_budget=30, include_preprocessors=None ):\n",
    "    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state=1)\n",
    "    \n",
    "    if include_preprocessors:\n",
    "        pipeline_optimizer = TPOTClassifier(max_time_mins = time_budget//60, generations=None,\n",
    "                                            use_dask=False,\n",
    "                                            n_jobs=-1,)\n",
    "    else:\n",
    "        pipeline_optimizer = TPOTClassifier(max_time_mins = time_budget//60, generations=None,\n",
    "                                    use_dask=False,\n",
    "                                    template='Classifier',\n",
    "                                    n_jobs=-1,)\n",
    "    \n",
    "    pipeline_optimizer.fit(X_train, y_train)\n",
    "    y_hat = pipeline_optimizer.predict(X_test)\n",
    "    acc = sklearn.metrics.accuracy_score(y_test, y_hat)\n",
    "    f1_s = sklearn.metrics.f1_score(y_test, y_hat, average='weighted')\n",
    "    metrs = []\n",
    "    metrs.append(\"Accuracy score - \" + str(acc))\n",
    "    metrs.append(\"F1 score - \" + str(f1_s))\n",
    "    res = [\"\",\"\",\"\",\"\",f1_s,acc,\"\",pipeline_optimizer.export()]\n",
    "    \n",
    "    \n",
    "    return str(metrs),res\n",
    "\n",
    "    \n",
    "def gen_feats_featools(df):\n",
    "    es = ft.EntitySet(id = 'df')\n",
    "    es.entity_from_dataframe(entity_id = 'data', dataframe = df, \n",
    "                         make_index = True, index = 'index')\n",
    "    feature_matrix, feature_defs = ft.dfs(entityset = es, target_entity = 'data', verbose = 1)\n",
    "                                      #agg_primitives=[\"mean\", \"max\", \"min\", \"std\", \"skew\"],\n",
    "                                     # trans_primitives = ['add_numeric', 'multiply_numeric'])\n",
    "    return feature_matrix\n",
    "\n",
    "def gen_feats_autofeat(X,y):\n",
    "    fsel = autofeat.FeatureSelector(verbose=1)\n",
    "    X = fsel.fit_transform(X,y)\n",
    "    return X\n",
    "    \n",
    "    \n",
    "def run_test(df_path,target_ft, mode = 0, time_budget=30,n_jobs=-1):\n",
    "    now = datetime.now()\n",
    "\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Start Time =\", current_time)\n",
    "    print(\"Time budget =\", time_budget//60)\n",
    "    results = []\n",
    "    df = pd.read_csv(df_path)\n",
    "    object_columns = df.select_dtypes(include='object')\n",
    "    if len(object_columns.columns):\n",
    "        df[object_columns.columns] = object_columns.apply(preprocessing.LabelEncoder().fit_transform)\n",
    "    X = df.drop(columns=target_ft)\n",
    "    y = df[target_ft]\n",
    "    res_df = []\n",
    "    autofeat_time = 0\n",
    "    \n",
    "    #if mode == 0 or mode == 1:\n",
    "    #    start = time.monotonic()\n",
    "    #    X_new = gen_feats_autofeat(X,y)\n",
    "    #    end = time.monotonic()\n",
    "    #    autofeat_time = int(end-start)\n",
    "    #    print(\"Autofeat_time: \",autofeat_time)\n",
    "    #    rs = run_as(X_new,y,target_ft,time_budget=time_budget, include_preprocessors =[\"no_preprocessing\"],n_jobs=n_jobs)\n",
    "    #    results.append(\"Autosk Only with Preprocessing: \" + rs[0])\n",
    "    #    rs[1][0] = df_path[5:-4]\n",
    "    #    rs[1][1] = str(time_budget/60)+'m'\n",
    "    #    rs[1][2] = \"Autofeat\"\n",
    "    #    rs[1][3] = \"AutoSK\"\n",
    "    #    rs[1][6] = str(X_new.shape)\n",
    "    #    res_df.append(rs[1])\n",
    "    \n",
    "\n",
    "    #if mode == 0 or mode == 2:\n",
    "    #    rs = run_as(X,y,target_ft, time_budget=time_budget+autofeat_time, include_preprocessors=None,n_jobs=n_jobs)   \n",
    "    #    results.append(\"Autosk Only with Preprocessing: \" + rs[0])\n",
    "    #    rs[1][0] = df_path[5:-4]\n",
    "    #    rs[1][1] = str(round((time_budget+autofeat_time)/60,2))+'m'\n",
    "    #    rs[1][2] = \"AutoSK\"\n",
    "    #    rs[1][3] = \"AutoSK\"\n",
    "    #    rs[1][6] = str(X.shape)\n",
    "    #    res_df.append(rs[1])\n",
    "    #if mode == 0 or mode == 3:\n",
    "    #    rs = run_as(X,y,target_ft,time_budget=time_budget, include_preprocessors =[\"no_preprocessing\"],n_jobs=n_jobs)\n",
    "    #    results.append(\"Autosk Only without Preprocessing: \" + rs[0])\n",
    "    #    rs[1][0] = df_path[5:-4]\n",
    "    #    rs[1][1] = str(round((time_budget+autofeat_time)/60,2))+'m'\n",
    "    #    rs[1][2] = \"None\"\n",
    "    #    rs[1][3] = \"AutoSK\"\n",
    "    #    rs[1][6] = str(X.shape)\n",
    "    #    res_df.append(rs[1])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #if mode == 0 or mode == 4:\n",
    "    #    X_new = gen_feats_featools(X)\n",
    "    #    rs = run_as(X_new,y,target_ft,time_budget=time_budget, include_preprocessors =[\"no_preprocessing\"])\n",
    "    #    results.append(\"Autosk with Featuretools: \" + rs)\n",
    "\n",
    "    \n",
    "\n",
    "    if mode ==0 or mode == 2:\n",
    "        start = time.monotonic()\n",
    "        X_new = gen_feats_autofeat(X,y)\n",
    "        end = time.monotonic()\n",
    "        autofeat_time = int(end-start)\n",
    "        start = time.monotonic()\n",
    "        rs = run_tpot(X_new,y,target_ft, time_budget=time_budget, include_preprocessors=None)   \n",
    "        end = time.monotonic()\n",
    "        print(\"Actual Time Taken: \",str(end-start))\n",
    "        results.append(\"TPOT with Autofeat: \" + rs[0])\n",
    "        rs[1][0] = df_path[5:-4]\n",
    "        rs[1][1] = str(round((time_budget+autofeat_time)/60,2))+'m'\n",
    "        rs[1][2] = \"AutoFeat\"\n",
    "        rs[1][3] = \"TPOT\"\n",
    "        rs[1][6] = str(X_new.shape)\n",
    "        res_df.append(rs[1])\n",
    "        \n",
    "    \n",
    "    \n",
    "    if mode ==0 or mode == 5:\n",
    "        start = time.monotonic()\n",
    "        rs = run_tpot(X,y,target_ft, time_budget=time_budget+autofeat_time, include_preprocessors=False)   \n",
    "        end = time.monotonic()\n",
    "        print(\"Actual Time Taken: \",str(end-start))\n",
    "        results.append(\"TPOT Only with No Preprocessing: \" + rs[0])\n",
    "        rs[1][0] = df_path[5:-4]\n",
    "        rs[1][1] = str(round((time_budget+autofeat_time)/60,2))+'m'\n",
    "        rs[1][2] = \"None\"\n",
    "        rs[1][3] = \"TPOT\"\n",
    "        rs[1][6] = str(X.shape)\n",
    "        res_df.append(rs[1])\n",
    "        \n",
    "        \n",
    "\n",
    "    if mode ==0 or mode == 1:\n",
    "        start = time.monotonic()\n",
    "        rs = run_tpot(X,y,target_ft, time_budget=time_budget+autofeat_time, include_preprocessors=True)   \n",
    "        end = time.monotonic()\n",
    "        print(\"Actual Time Taken: \",str(end-start))\n",
    "        results.append(\"TPOT Only with Preprocessing: \" + rs[0])\n",
    "        rs[1][0] = df_path[5:-4]\n",
    "        rs[1][1] = str(round((time_budget+autofeat_time)/60,2))+'m'\n",
    "        rs[1][2] = \"TPOT\"\n",
    "        rs[1][3] = \"TPOT\"\n",
    "        rs[1][6] = str(X.shape)\n",
    "        res_df.append(rs[1])\n",
    "        \n",
    "          \n",
    "    \n",
    "    \n",
    "        \n",
    "    print(\"===================================\")\n",
    "    print(\"Time budeget: \",time_budget)\n",
    "    [print(x) for x in results]\n",
    "    \n",
    "    res_df =  pd.DataFrame(res_df, columns = [\"Dataset\",\"Time\",\"Preprocessing\",\"AutoML\",\"Accuracy\",\"F1\",\"Shape\",\"PipeLine\"])\n",
    "    res_df.drop(columns=[\"PipeLine\"]).to_csv(\"results/\"+df_path[5:])\n",
    "    res_df.to_csv(\"results/pipe_\"+df_path[5:])\n",
    "    \n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -r tmp\n",
    "#df_path = \"data/gina.csv\"\n",
    "#target_ft = \"class\"\n",
    "#res = run_test(df_path, target_ft, mode=2 ,n_jobs=-1,time_budget=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_path = \"data/gina.csv\"\n",
    "#target_ft = \"class\"\n",
    "#res = run_test(df_path, target_ft, mode=5 ,n_jobs=-1,time_budget=3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -r tmp\n",
    "#df = pd.read_csv(\"blood.csv\")\n",
    "#target_ft = \"class\"\n",
    "#run_test(df, target_ft, mode=2, time_budget=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"winequality-red.csv\")\n",
    "#target_ft = \"quality\"\n",
    "#run_test(df, target_ft, mode=2 ,time_budget=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"data/airlines.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -r tmp\n",
    "#df = pd.read_csv(\"data/airlines.csv\").drop(columns=[\"Airline\",\"AirportFrom\",\"AirportTo\"])\n",
    "#target_ft = \"Delay\"\n",
    "#run_test(df, target_ft, mode=2 ,time_budget=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -r tmp\n",
    "#df = \"data/gina.csv\"\n",
    "#target_ft = \"class\"\n",
    "#run_test(df, target_ft, mode=2 ,time_budget=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -r tmp\n",
    "#df = pd.read_csv(\"data/gina.csv\")\n",
    "#target_ft = \"class\"\n",
    "#run_test(df, target_ft, mode=4 ,time_budget=420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -r tmp\n",
    "#df_path = \"data/20_newsgroups.csv\"\n",
    "#target_ft = \"class\"\n",
    "#res = run_test(df_path, target_ft, mode=2 ,time_budget=120, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time = 20:25:42\n",
      "Time budget = 60\n",
      "[featsel] Scaling data...done.\n",
      "[featsel] Feature selection run 1/5\n",
      "[featsel] Feature selection run 2/5\n",
      "[featsel] Feature selection run 3/5\n",
      "[featsel] Feature selection run 4/5\n",
      "[featsel] Feature selection run 5/5\n"
     ]
    }
   ],
   "source": [
    "df_path = \"data/20_newsgroups.csv\"\n",
    "#df_path = \"data/gina.csv\"\n",
    "\n",
    "target_ft = \"class\"\n",
    "res = run_test(df_path, target_ft, mode=0 ,n_jobs=-1,time_budget=3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
