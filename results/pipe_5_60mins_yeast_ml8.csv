,Dataset,Time,Preprocessing,AutoML,Accuracy,F1,Shape,PipeLine
0,yeast_ml8,60.08m,AutoFeat,AutoSK,0.9826782904996463,0.9884297520661157,"(2417, 8)","[(1.000000, MyDummyClassifier(configuration=1, init_params=None, random_state=None)),
]"
1,yeast_ml8,60.08m,None,AutoSK,0.9826782904996463,0.9884297520661157,"(2417, 116)","[(1.000000, MyDummyClassifier(configuration=1, init_params=None, random_state=None)),
]"
2,yeast_ml8,60.08m,AutoSK,AutoSK,0.9826782904996463,0.9884297520661157,"(2417, 116)","[(0.560000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'classifier:__choice__': 'lda', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize', 'feature_preprocessor:__choice__': 'kitchen_sinks', 'classifier:lda:n_components': 181, 'classifier:lda:shrinkage': 'None', 'classifier:lda:tol': 0.003818536419351982, 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0006686205232668009, 'feature_preprocessor:kitchen_sinks:gamma': 0.0003259229177587619, 'feature_preprocessor:kitchen_sinks:n_components': 96},
dataset_properties={
  'task': 1,
  'sparse': False,
  'multilabel': False,
  'multiclass': False,
  'target_type': 'classification',
  'signed': False})),
(0.440000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'classifier:__choice__': 'lda', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize', 'feature_preprocessor:__choice__': 'extra_trees_preproc_for_classification', 'classifier:lda:n_components': 77, 'classifier:lda:shrinkage': 'auto', 'classifier:lda:tol': 0.003118347625632949, 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00026534557359388333, 'feature_preprocessor:extra_trees_preproc_for_classification:bootstrap': 'False', 'feature_preprocessor:extra_trees_preproc_for_classification:criterion': 'gini', 'feature_preprocessor:extra_trees_preproc_for_classification:max_depth': 'None', 'feature_preprocessor:extra_trees_preproc_for_classification:max_features': 0.9835502986442681, 'feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes': 'None', 'feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease': 0.0, 'feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf': 8, 'feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split': 20, 'feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf': 0.0, 'feature_preprocessor:extra_trees_preproc_for_classification:n_estimators': 100},
dataset_properties={
  'task': 1,
  'sparse': False,
  'multilabel': False,
  'multiclass': False,
  'target_type': 'classification',
  'signed': False})),
]"
3,yeast_ml8,60.08m,AutoFeat,TPOT,0.9868664658565334,0.9884297520661157,"(2417, 8)","import numpy as np
import pandas as pd
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import train_test_split

# NOTE: Make sure that the outcome column is labeled 'target' in the data file
tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)
features = tpot_data.drop('target', axis=1)
training_features, testing_features, training_target, testing_target = \
            train_test_split(features, tpot_data['target'], random_state=None)

# Average CV score on the training set was: 0.9873110816857679
exported_pipeline = GradientBoostingClassifier(learning_rate=0.1, max_depth=5, max_features=0.2, min_samples_leaf=12, min_samples_split=13, n_estimators=100, subsample=0.3)

exported_pipeline.fit(training_features, training_target)
results = exported_pipeline.predict(testing_features)
"
4,yeast_ml8,60.08m,None,TPOT,0.9826782904996463,0.9884297520661157,"(2417, 116)","import numpy as np
import pandas as pd
from sklearn.linear_model import SGDClassifier
from sklearn.model_selection import train_test_split

# NOTE: Make sure that the outcome column is labeled 'target' in the data file
tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)
features = tpot_data.drop('target', axis=1)
training_features, testing_features, training_target, testing_target = \
            train_test_split(features, tpot_data['target'], random_state=None)

# Average CV score on the training set was: 0.9856536231222319
exported_pipeline = SGDClassifier(alpha=0.0, eta0=0.01, fit_intercept=True, l1_ratio=0.0, learning_rate=""constant"", loss=""modified_huber"", penalty=""elasticnet"", power_t=0.0)

exported_pipeline.fit(training_features, training_target)
results = exported_pipeline.predict(testing_features)
"
5,yeast_ml8,60.08m,TPOT,TPOT,0.9826782904996463,0.9884297520661157,"(2417, 116)","import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import LinearSVC

# NOTE: Make sure that the outcome column is labeled 'target' in the data file
tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)
features = tpot_data.drop('target', axis=1)
training_features, testing_features, training_target, testing_target = \
            train_test_split(features, tpot_data['target'], random_state=None)

# Average CV score on the training set was: 0.9851011369343865
exported_pipeline = LinearSVC(C=0.5, dual=False, loss=""squared_hinge"", penalty=""l1"", tol=0.01)

exported_pipeline.fit(training_features, training_target)
results = exported_pipeline.predict(testing_features)
"
